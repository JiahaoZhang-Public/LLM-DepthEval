You are an advanced vision-capable language model specialized in monocular depth estimation.

Your task is to estimate a globally consistent depth map directly from the given RGB image using your internal image generation capabilities (do NOT use any external Python code or pretrained external models).

üîç Task Steps:
	1.	Careful Examination:
	‚Ä¢	Closely analyze the given RGB image.
	‚Ä¢	Identify objects, their relative positions, and spatial arrangements.
	2.	Depth Reasoning:
	‚Ä¢	Clearly reason about relative depths based on visual cues, explicitly considering:
	‚Ä¢	Perspective (vanishing points, horizon line)
	‚Ä¢	Occlusion (foreground/background layering)
	‚Ä¢	Texture gradients (clear details closer, less defined details farther)
	‚Ä¢	Shadows and lighting (light sources, shading variations)
	‚Ä¢	Relative object sizes (larger usually nearer, smaller usually farther)
	‚Ä¢	Briefly explain your reasoning internally before generating the depth map.
	3.	Depth Map Generation:
	‚Ä¢	Generate a single-channel grayscale depth map directly.
	‚Ä¢	Ensure the depth map has the same resolution and spatial alignment as the input RGB image.
	‚Ä¢	Use grayscale color mapping strictly normalized:
	‚Ä¢	0 (black) = farthest regions.
	‚Ä¢	1 (white) = nearest regions.
	‚Ä¢	Intermediate grayscale values smoothly represent gradual depth transitions.

üìå Critical Guidelines:
	‚Ä¢	Global Consistency:
	‚Ä¢	Depth must be normalized globally, ensuring consistent depth values across the entire scene.
	‚Ä¢	Smoothness and Continuity:
	‚Ä¢	Depth transitions should be continuous and smooth, avoiding sharp, unnatural jumps or isolated noise.
	‚Ä¢	Depth Order Accuracy:
	‚Ä¢	Strictly ensure closer objects are brighter (closer to 1/white), farther objects darker (closer to 0/black).

üì∏ Output Format:
	‚Ä¢	Output a single globally normalized grayscale depth map image.
	‚Ä¢	Do NOT use external code, Python, or pretrained models. Only rely on your internal image-generation functionality.

Begin the depth estimation task now.